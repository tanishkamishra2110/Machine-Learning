{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d5fe6e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0, Cost: 1484.5865574086486\n",
      "Iteration: 1, Cost: 457.8542575737672\n",
      "Iteration: 2, Cost: 199.5099857255389\n",
      "Iteration: 3, Cost: 134.50591058200533\n",
      "Iteration: 4, Cost: 118.1496934223995\n",
      "Iteration: 5, Cost: 114.0341490603815\n",
      "Iteration: 6, Cost: 112.99857731713657\n",
      "Iteration: 7, Cost: 112.73798187568467\n",
      "Iteration: 8, Cost: 112.6723843590911\n",
      "Iteration: 9, Cost: 112.65585181499745\n",
      "Iteration: 10, Cost: 112.65166489759581\n",
      "Iteration: 11, Cost: 112.6505843615011\n",
      "Iteration: 12, Cost: 112.65028544701502\n",
      "Iteration: 13, Cost: 112.65018320293967\n",
      "Iteration: 14, Cost: 112.650130445072\n",
      "Iteration: 15, Cost: 112.65009013922885\n",
      "Iteration: 16, Cost: 112.6500529669463\n",
      "Iteration: 17, Cost: 112.65001658353178\n",
      "Iteration: 18, Cost: 112.64998039901865\n",
      "Iteration: 19, Cost: 112.64994426496071\n",
      "Iteration: 20, Cost: 112.64990814400622\n",
      "Iteration: 21, Cost: 112.64987202675677\n",
      "Iteration: 22, Cost: 112.64983591084761\n",
      "Iteration: 23, Cost: 112.64979979568368\n",
      "Iteration: 24, Cost: 112.64976368111523\n",
      "Iteration: 25, Cost: 112.64972756710469\n",
      "Iteration: 26, Cost: 112.64969145364236\n",
      "Iteration: 27, Cost: 112.64965534072611\n",
      "Iteration: 28, Cost: 112.64961922835512\n",
      "Iteration: 29, Cost: 112.64958311652944\n",
      "Iteration: 30, Cost: 112.64954700524868\n",
      "Iteration: 31, Cost: 112.64951089451318\n",
      "Iteration: 32, Cost: 112.64947478432279\n",
      "Iteration: 33, Cost: 112.64943867467744\n",
      "Iteration: 34, Cost: 112.64940256557728\n",
      "Iteration: 35, Cost: 112.64936645702221\n",
      "Iteration: 36, Cost: 112.64933034901203\n",
      "Iteration: 37, Cost: 112.64929424154704\n",
      "Iteration: 38, Cost: 112.64925813462712\n",
      "Iteration: 39, Cost: 112.6492220282522\n",
      "Iteration: 40, Cost: 112.64918592242235\n",
      "Iteration: 41, Cost: 112.64914981713754\n",
      "Iteration: 42, Cost: 112.64911371239779\n",
      "Iteration: 43, Cost: 112.64907760820296\n",
      "Iteration: 44, Cost: 112.64904150455324\n",
      "Iteration: 45, Cost: 112.64900540144845\n",
      "Iteration: 46, Cost: 112.64896929888867\n",
      "Iteration: 47, Cost: 112.64893319687388\n",
      "Iteration: 48, Cost: 112.6488970954041\n",
      "Iteration: 49, Cost: 112.64886099447922\n",
      "Iteration: 50, Cost: 112.64882489409929\n",
      "Iteration: 51, Cost: 112.64878879426433\n",
      "Iteration: 52, Cost: 112.64875269497436\n",
      "Iteration: 53, Cost: 112.64871659622933\n",
      "Iteration: 54, Cost: 112.64868049802914\n",
      "Iteration: 55, Cost: 112.648644400374\n",
      "Iteration: 56, Cost: 112.64860830326366\n",
      "Iteration: 57, Cost: 112.64857220669828\n",
      "Iteration: 58, Cost: 112.64853611067772\n",
      "Iteration: 59, Cost: 112.64850001520212\n",
      "Iteration: 60, Cost: 112.64846392027131\n",
      "Iteration: 61, Cost: 112.64842782588545\n",
      "Iteration: 62, Cost: 112.64839173204442\n",
      "Iteration: 63, Cost: 112.6483556387483\n",
      "Iteration: 64, Cost: 112.64831954599697\n",
      "Iteration: 65, Cost: 112.64828345379043\n",
      "Iteration: 66, Cost: 112.64824736212877\n",
      "Iteration: 67, Cost: 112.64821127101193\n",
      "Iteration: 68, Cost: 112.64817518043986\n",
      "Iteration: 69, Cost: 112.64813909041264\n",
      "Iteration: 70, Cost: 112.64810300093015\n",
      "Iteration: 71, Cost: 112.64806691199259\n",
      "Iteration: 72, Cost: 112.64803082359971\n",
      "Iteration: 73, Cost: 112.64799473575155\n",
      "Iteration: 74, Cost: 112.64795864844827\n",
      "Iteration: 75, Cost: 112.64792256168963\n",
      "Iteration: 76, Cost: 112.64788647547579\n",
      "Iteration: 77, Cost: 112.64785038980668\n",
      "Iteration: 78, Cost: 112.64781430468226\n",
      "Iteration: 79, Cost: 112.64777822010265\n",
      "Iteration: 80, Cost: 112.6477421360677\n",
      "Iteration: 81, Cost: 112.64770605257743\n",
      "Iteration: 82, Cost: 112.64766996963193\n",
      "Iteration: 83, Cost: 112.64763388723107\n",
      "Iteration: 84, Cost: 112.64759780537483\n",
      "Iteration: 85, Cost: 112.64756172406335\n",
      "Iteration: 86, Cost: 112.6475256432965\n",
      "Iteration: 87, Cost: 112.64748956307432\n",
      "Iteration: 88, Cost: 112.64745348339677\n",
      "Iteration: 89, Cost: 112.64741740426388\n",
      "Iteration: 90, Cost: 112.6473813256756\n",
      "Iteration: 91, Cost: 112.64734524763193\n",
      "Iteration: 92, Cost: 112.64730917013293\n",
      "Iteration: 93, Cost: 112.6472730931785\n",
      "Iteration: 94, Cost: 112.64723701676861\n",
      "Iteration: 95, Cost: 112.64720094090339\n",
      "Iteration: 96, Cost: 112.64716486558265\n",
      "Iteration: 97, Cost: 112.64712879080662\n",
      "Iteration: 98, Cost: 112.64709271657513\n",
      "Iteration: 99, Cost: 112.64705664288809\n",
      "Final slope: 1.4788027175308358, Final intercept: 0.035074970592341756\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def cost(points, m, c):\n",
    "    total_cost = 0\n",
    "    M = len(points)\n",
    "    for i in range(M):\n",
    "        x = points[i, 0]\n",
    "        y = points[i, 1]\n",
    "        total_cost += (1/M)*((y - m*x - c)**2)\n",
    "    return total_cost\n",
    "\n",
    "def step_gradient(points, learning_rate, m, c):\n",
    "    m_slope = 0\n",
    "    c_slope = 0\n",
    "    M = len(points)\n",
    "    for i in range(M):\n",
    "        x = points[i, 0]\n",
    "        y = points[i, 1]\n",
    "        m_slope += (-2/M) * (y - m * x - c) * x\n",
    "        c_slope += (-2/M) * (y - m * x - c)\n",
    "    new_m = m - learning_rate * m_slope\n",
    "    new_c = c - learning_rate * c_slope\n",
    "    return new_m, new_c\n",
    "\n",
    "def gd(points, learning_rate, num_iterations):\n",
    "    m = 0\n",
    "    c = 0\n",
    "    for i in range(num_iterations):\n",
    "        m, c = step_gradient(points, learning_rate, m, c)\n",
    "        print(f\"Iteration: {i}, Cost: {cost(points, m, c)}\")\n",
    "    return m, c\n",
    "\n",
    "def run():\n",
    "    data = np.loadtxt(\"data.csv\", delimiter=\",\")\n",
    "    learning_rate = 0.0001\n",
    "    num_iterations = 100\n",
    "    m, c = gd(data, learning_rate, num_iterations)\n",
    "    print(f\"Final slope: {m}, Final intercept: {c}\")\n",
    "\n",
    "run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464ae369",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
